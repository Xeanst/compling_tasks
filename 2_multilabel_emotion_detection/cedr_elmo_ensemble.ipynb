{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом блокноте рассматривается распознавание эмоций на корпусе CEDR с помощью векторных представлений ELMo и ансамбля классификаторов на основе разных алгоритмов. Корпус и подход описаны в статье [\"Data-Driven Model for Emotion Detection in Russian Texts\"](https://www.sciencedirect.com/science/article/pii/S1877050921013247).\n",
    "\n",
    "Обученные модели доступны по ссылкам:\n",
    "- [elmo_vec.pkl](https://canvas.instructure.com/courses/7745797/files/228148829?module_item_id=94185010)\n",
    "- [joy_model.pkl](https://canvas.instructure.com/courses/7745797/files/228148847?module_item_id=94185018)\n",
    "- [sad_model.pkl](https://canvas.instructure.com/courses/7745797/files/228148879?module_item_id=94185037)\n",
    "- [surprise_model.pkl](https://canvas.instructure.com/courses/7745797/files/228148898?module_item_id=94185056)\n",
    "- [fear_model.pkl](https://canvas.instructure.com/courses/7745797/files/228148913?module_item_id=94185063)\n",
    "- [anger_model.pkl](https://canvas.instructure.com/courses/7745797/files/228148917?module_item_id=94185064)\n",
    "\n",
    "Их необходимо скачать и поместить в одну папку.\n",
    "\n",
    "Для запуска блокнота требуется версия питона 3.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Установка библиотек"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование моделей возможно только с определенными версиями библиотек, их необходимо установить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "huggingface-hub 0.17.1 requires packaging>=20.9, but you'll have packaging 20.4 which is incompatible.\n",
      "datasets 2.14.5 requires tqdm>=4.62.1, but you'll have tqdm 4.59.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install TPOT==0.11.1 xgboost==0.90 numpy==1.21.2 scikit-learn==0.22.1 scipy==1.10.1 deap==1.3.3 pandas==2.0.3 joblib==1.3.1 tqdm==4.59 -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Набор данных доступен в библиотеке Datasets от Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "huggingface-hub 0.17.1 requires packaging>=20.9, but you'll have packaging 20.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для загрузки набора данных используется метод load_dataset. Для классификации понадобится тестовая выборка основного корпуса, а также словарь, где указано соответствие числовых меток и классов эмоций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "test_data = load_dataset('cedr', split='test')\n",
    "\n",
    "labels2emotion = {0: \"joy\", 1: \"sadness\", 2: \"surprise\", 3: \"fear\", 4: \"anger\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для загрузки модели используется модуль pickle. Формат pickle позволяет хранить любые объекты Python. Одной из его главных функций является сохранение модели машинного обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_model(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В переменной path_to_data нужно указать путь к папке, в которой сохранены модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = 'C:/models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно загрузить все модели и посмотреть, какие алгоритмы использовались для их обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.01,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joy_model = load_model(f'{path_to_data}/joy_model.pkl')\n",
    "joy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sad_model = load_model(f'{path_to_data}/sad_model.pkl')\n",
    "sad_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('robustscaler',\n",
       "                 RobustScaler(copy=True, quantile_range=(25.0, 75.0),\n",
       "                              with_centering=True, with_scaling=True)),\n",
       "                ('stackingestimator',\n",
       "                 StackingEstimator(estimator=LogisticRegression(C=0.01,\n",
       "                                                                class_weight=None,\n",
       "                                                                dual=False,\n",
       "                                                                fit_intercept=True,\n",
       "                                                                intercept_scaling=1,\n",
       "                                                                l1_ratio=None,\n",
       "                                                                max_iter=100,\n",
       "                                                                multi_class='auto',\n",
       "                                                                n_jobs=None,\n",
       "                                                                penalty='l2',\n",
       "                                                                ra...\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0, learning_rate=0.01,\n",
       "                               max_delta_step=0, max_depth=5,\n",
       "                               min_child_weight=9, missing=nan,\n",
       "                               n_estimators=100, n_jobs=1, nthread=1,\n",
       "                               objective='binary:logistic', random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               seed=None, silent=None, subsample=0.1,\n",
       "                               verbosity=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise_model = load_model(f'{path_to_data}/surprise_model.pkl')\n",
    "surprise_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('pca',\n",
       "                 PCA(copy=True, iterated_power=5, n_components=None,\n",
       "                     random_state=None, svd_solver='randomized', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('sgdclassifier',\n",
       "                 SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
       "                               early_stopping=False, epsilon=0.1, eta0=0.01,\n",
       "                               fit_intercept=True, l1_ratio=0.25,\n",
       "                               learning_rate='constant', loss='squared_hinge',\n",
       "                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "                               penalty='elasticnet', power_t=0.5,\n",
       "                               random_state=None, shuffle=True, tol=0.001,\n",
       "                               validation_fraction=0.1, verbose=0,\n",
       "                               warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fear_model = load_model(f'{path_to_data}/fear_model.pkl')\n",
    "fear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=20.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anger_model = load_model(f'{path_to_data}/anger_model.pkl')\n",
    "anger_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Файл с векторами ELMo представляет собой словарь с двумя ключами: train и test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'test'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_model(f'{path_to_data}/elmo_vec.pkl')\n",
    "df.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждое значение словаря является списком, длина списка равна количеству объектов в соответствующей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7528"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1882"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый элемент списка представляет собой словарь из векторов и эмоциональных меток."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vec': array([-0.2145    ,  0.10968809,  0.08183508, ..., -0.24737515,\n",
       "        -0.05388971,  0.26529486]),\n",
       " 'labels': ['sadness']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['train'][94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vec': array([-0.31789889, -0.16927155,  0.37030656, ..., -0.2655307 ,\n",
       "        -0.20555632,  0.28399004]),\n",
       " 'labels': ['joy']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['test'][67]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторное представление и название класса можно получить по соответствующему ключу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.21446268, -0.06942602,  0.29757945, ..., -0.20662831,\n",
       "       -0.25054309, -0.04707903])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['test'][95]['vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['surprise']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['test'][95]['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применение моделей для классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion \"joy\":\n",
      "mic.: 0.92;\t mac.:0.87\n",
      "\n",
      "Emotion \"sadness\":\n",
      "mic.: 0.92;\t mac.:0.86\n",
      "\n",
      "Emotion \"surprise\":\n",
      "mic.: 0.93;\t mac.:0.76\n",
      "\n",
      "Emotion \"fear\":\n",
      "mic.: 0.93;\t mac.:0.73\n",
      "\n",
      "Emotion \"anger\":\n",
      "mic.: 0.9;\t mac.:0.62\n",
      "\n",
      "No emotion\n",
      "F-score\t micro: 0.77;\tmacro:0.77\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         joy       0.85      0.72      0.78       353\n",
      "     sadness       0.85      0.72      0.78       379\n",
      "    surprise       0.59      0.54      0.57       170\n",
      "        fear       0.58      0.44      0.50       141\n",
      "       anger       0.27      0.31      0.29       125\n",
      "  no emotion       0.65      0.86      0.74       734\n",
      "\n",
      "   micro avg       0.68      0.71      0.69      1902\n",
      "   macro avg       0.63      0.60      0.61      1902\n",
      "weighted avg       0.69      0.71      0.69      1902\n",
      " samples avg       0.69      0.71      0.70      1902\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "# матрица для записи правильных и предсказанных ответов\n",
    "# её размер — количество объектов х количество классов\n",
    "all_true = np.zeros((1882,6))\n",
    "all_pred = np.zeros((1882,6))\n",
    "\n",
    "# будем осуществлять проход по всем предложениям 5 раз (по количеству эмоций)\n",
    "for key, value in labels2emotion.items():\n",
    "    if value == 'joy':\n",
    "        model = joy_model\n",
    "    elif value == 'sadness':\n",
    "        model = sad_model\n",
    "    elif value == 'surprise':\n",
    "        model = surprise_model\n",
    "    elif value == 'fear':\n",
    "        model = fear_model\n",
    "    elif value == 'anger':\n",
    "        model = anger_model\n",
    "        \n",
    "    # векторы текстов и ответы тестовой выборки\n",
    "    test_x, test_y = [], []\n",
    "    \n",
    "    # добавляем предложения в тестовую выборку\n",
    "    for sample in df['test']:\n",
    "        test_x.append(sample['vec'])\n",
    "        # для каждого предложения проверяем наличие эмоции среди списка меток\n",
    "        if value in sample['labels']:\n",
    "            test_y.append(1)\n",
    "        else:\n",
    "            test_y.append(0)\n",
    "    \n",
    "    # записываем предсказания обученной модели\n",
    "    pred_y = model.predict(np.array(test_x))\n",
    "    \n",
    "    # подсчитываем микро- и макроусредненную F-меру\n",
    "    f_micro = f1_score(test_y, pred_y, average=\"micro\")\n",
    "    f_macro = f1_score(test_y, pred_y, average=\"macro\")\n",
    "    # выводим название класса и значения метрик\n",
    "    print(f'Emotion \"{value}\":')\n",
    "    print(f'mic.: {round(f_micro, 2)};\\t mac.:{round(f_macro, 2)}\\n')\n",
    "    \n",
    "    # записываем ответы для всех объектов в столбец с соответвующим индексом\n",
    "    all_true[:, key] = np.array(test_y)\n",
    "    all_pred[:, key] = pred_y\n",
    "\n",
    "# ответы для нейтрального класса определяются по остаточному принципу\n",
    "# если сумма всех меток эмоций равна нулю, то присваивается нейтральный класс\n",
    "all_pred[:, 5] = (np.sum(all_pred[:,:], axis=1)==0).astype(int)\n",
    "all_true[:, 5] = (np.sum(all_true[:,:], axis=1)==0).astype(int)\n",
    "# считаем и выводим метрики\n",
    "f_micro = f1_score(all_true[:, 5], all_pred[:, 5], average=\"micro\")\n",
    "f_macro = f1_score(all_true[:, 5], all_pred[:, 5], average=\"macro\")\n",
    "print(f'No emotion')\n",
    "print(f'F-score\\t micro: {round(f_micro, 2)};\\tmacro:{round(f_macro, 2)}\\n')\n",
    "\n",
    "# выводим отчет о классификации\n",
    "target_names = [\"joy\", \"sadness\", \"surprise\", \"fear\", \"anger\", \"no emotion\"]\n",
    "print(classification_report(all_true, all_pred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
